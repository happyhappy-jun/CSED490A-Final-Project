{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('data/classificaition_train_x.csv')\n",
    "train_y = pd.read_csv('data/classificaition_train_y.csv')\n",
    "val_x = pd.read_csv('data/classificaition_val_x.csv')\n",
    "val_y = pd.read_csv('data/classificaition_val_y.csv')\n",
    "train = pd.concat([train_x, train_y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x13aba4090>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "save = train[train['f10']!=899.1]\n",
    "# sns.countplot(hue = 'y', x = 'f10', data = save)\n",
    "discretized = pd.qcut(save['f10'],\n",
    "                            q=[0,.4, 1],\n",
    "                            labels=False,\n",
    "                            precision=0)\n",
    "save.insert(save.columns.get_loc('f10'), \"f10_dis\", discretized)\n",
    "sns.countplot(hue = 'y', x = 'f10_dis', data = save)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def f10(df):\n",
    "    b = df[df['f10']!=899.1].quantile(0.4)['f10']\n",
    "    dis = pd.cut(df['f10'], bins=[-99999, b, 899, 999999], labels=[0, 1,2])\n",
    "    df['f10'] = dis\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def catagorize(df):\n",
    "    catags = []\n",
    "    for col in list(df.columns):\n",
    "        if(type(df[col][0])==str):\n",
    "            catags.append(col)\n",
    "    cols = list(df.columns)\n",
    "    quant = [i for i in cols if i not in catags]\n",
    "    return (catags, quant)\n",
    "\n",
    "def encoder(df):\n",
    "    catags = catagorize(df)[0]\n",
    "    temp = df.copy()\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    \n",
    "    for col in catags:\n",
    "        temp[col] = enc.fit_transform(temp[col])\n",
    "    return temp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x13ccf70d0>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "sns.countplot(y='f19', data=train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def remove_unknown(df):\n",
    "    remove_cand = [('f1', 'c11'),  ('f7', 'c2')]\n",
    "    remove = [('f3', 'c1'), ('f4', 'c4'), ('f9', 'c3'), ('f11', 5176.3), ('f15', 0.2)]\n",
    "    for r in remove:\n",
    "        df = df[df[r[0]] != r[1]]\n",
    "    df = df[df['f19'] < 4]\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "        f1  f2  f3  f4  f5  f6  f7  f8  f9 f10  ...  f12      f13    f14  f15  \\\n0      c11  c0  c0  c7  53   1  c0  c3  c2   2  ...   c1  65.7426 -34.16  1.4   \n1       c5  c1  c2  c0  48  17  c1  c0  c1   2  ...   c1  65.7426 -34.16  1.4   \n2       c0  c0  c0  c6  29   1  c0  c2  c2   2  ...   c0  65.0251 -36.96 -1.8   \n3       c1  c0  c0  c2  25   2  c1  c3  c2   2  ...   c1  65.7426 -34.16  1.4   \n4       c6  c0  c0  c6  40   3  c0  c0  c2   2  ...   c1  65.1525 -37.68 -1.8   \n...    ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...      ...    ...  ...   \n26355   c1  c1  c0  c0  28   1  c0  c4  c0   2  ...   c0  65.7426 -34.16  1.4   \n26356   c9  c1  c2  c2  31   9  c0  c0  c1   2  ...   c1  65.7958 -29.12  1.1   \n26357   c4  c1  c2  c3  33   1  c0  c2  c1   2  ...   c1  65.7958 -29.12  1.1   \n26358   c9  c0  c0  c7  53   6  c0  c0  c0   2  ...   c1  65.0251 -36.96 -1.8   \n26359   c7  c1  c0  c3  30   2  c0  c2  c2   2  ...   c1  65.7958 -29.12  1.1   \n\n          f16  f17  f18  f19  f20  y  \n0      2.9772   c1  343    0   c6  0  \n1      2.9772   c1   27    0   c6  0  \n2      0.8004   c0  401    1   c4  0  \n3      2.9772   c1  212    0   c6  0  \n4      0.8430   c1  379    0   c3  0  \n...       ...  ...  ...  ...  ... ..  \n26355  2.9754   c1  327    0   c6  0  \n26356  2.9148   c1  179    0   c4  0  \n26357  2.9148   c1  641    0   c4  0  \n26358  0.7464   c1   35    0   c4  0  \n26359  2.9148   c1  190    0   c4  0  \n\n[26360 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>f5</th>\n      <th>f6</th>\n      <th>f7</th>\n      <th>f8</th>\n      <th>f9</th>\n      <th>f10</th>\n      <th>...</th>\n      <th>f12</th>\n      <th>f13</th>\n      <th>f14</th>\n      <th>f15</th>\n      <th>f16</th>\n      <th>f17</th>\n      <th>f18</th>\n      <th>f19</th>\n      <th>f20</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>c11</td>\n      <td>c0</td>\n      <td>c0</td>\n      <td>c7</td>\n      <td>53</td>\n      <td>1</td>\n      <td>c0</td>\n      <td>c3</td>\n      <td>c2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>c1</td>\n      <td>65.7426</td>\n      <td>-34.16</td>\n      <td>1.4</td>\n      <td>2.9772</td>\n      <td>c1</td>\n      <td>343</td>\n      <td>0</td>\n      <td>c6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>c5</td>\n      <td>c1</td>\n      <td>c2</td>\n      <td>c0</td>\n      <td>48</td>\n      <td>17</td>\n      <td>c1</td>\n      <td>c0</td>\n      <td>c1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>c1</td>\n      <td>65.7426</td>\n      <td>-34.16</td>\n      <td>1.4</td>\n      <td>2.9772</td>\n      <td>c1</td>\n      <td>27</td>\n      <td>0</td>\n      <td>c6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c0</td>\n      <td>c0</td>\n      <td>c0</td>\n      <td>c6</td>\n      <td>29</td>\n      <td>1</td>\n      <td>c0</td>\n      <td>c2</td>\n      <td>c2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>c0</td>\n      <td>65.0251</td>\n      <td>-36.96</td>\n      <td>-1.8</td>\n      <td>0.8004</td>\n      <td>c0</td>\n      <td>401</td>\n      <td>1</td>\n      <td>c4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>c1</td>\n      <td>c0</td>\n      <td>c0</td>\n      <td>c2</td>\n      <td>25</td>\n      <td>2</td>\n      <td>c1</td>\n      <td>c3</td>\n      <td>c2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>c1</td>\n      <td>65.7426</td>\n      <td>-34.16</td>\n      <td>1.4</td>\n      <td>2.9772</td>\n      <td>c1</td>\n      <td>212</td>\n      <td>0</td>\n      <td>c6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c6</td>\n      <td>c0</td>\n      <td>c0</td>\n      <td>c6</td>\n      <td>40</td>\n      <td>3</td>\n      <td>c0</td>\n      <td>c0</td>\n      <td>c2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>c1</td>\n      <td>65.1525</td>\n      <td>-37.68</td>\n      <td>-1.8</td>\n      <td>0.8430</td>\n      <td>c1</td>\n      <td>379</td>\n      <td>0</td>\n      <td>c3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26355</th>\n      <td>c1</td>\n      <td>c1</td>\n      <td>c0</td>\n      <td>c0</td>\n      <td>28</td>\n      <td>1</td>\n      <td>c0</td>\n      <td>c4</td>\n      <td>c0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>c0</td>\n      <td>65.7426</td>\n      <td>-34.16</td>\n      <td>1.4</td>\n      <td>2.9754</td>\n      <td>c1</td>\n      <td>327</td>\n      <td>0</td>\n      <td>c6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26356</th>\n      <td>c9</td>\n      <td>c1</td>\n      <td>c2</td>\n      <td>c2</td>\n      <td>31</td>\n      <td>9</td>\n      <td>c0</td>\n      <td>c0</td>\n      <td>c1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>c1</td>\n      <td>65.7958</td>\n      <td>-29.12</td>\n      <td>1.1</td>\n      <td>2.9148</td>\n      <td>c1</td>\n      <td>179</td>\n      <td>0</td>\n      <td>c4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26357</th>\n      <td>c4</td>\n      <td>c1</td>\n      <td>c2</td>\n      <td>c3</td>\n      <td>33</td>\n      <td>1</td>\n      <td>c0</td>\n      <td>c2</td>\n      <td>c1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>c1</td>\n      <td>65.7958</td>\n      <td>-29.12</td>\n      <td>1.1</td>\n      <td>2.9148</td>\n      <td>c1</td>\n      <td>641</td>\n      <td>0</td>\n      <td>c4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26358</th>\n      <td>c9</td>\n      <td>c0</td>\n      <td>c0</td>\n      <td>c7</td>\n      <td>53</td>\n      <td>6</td>\n      <td>c0</td>\n      <td>c0</td>\n      <td>c0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>c1</td>\n      <td>65.0251</td>\n      <td>-36.96</td>\n      <td>-1.8</td>\n      <td>0.7464</td>\n      <td>c1</td>\n      <td>35</td>\n      <td>0</td>\n      <td>c4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26359</th>\n      <td>c7</td>\n      <td>c1</td>\n      <td>c0</td>\n      <td>c3</td>\n      <td>30</td>\n      <td>2</td>\n      <td>c0</td>\n      <td>c2</td>\n      <td>c2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>c1</td>\n      <td>65.7958</td>\n      <td>-29.12</td>\n      <td>1.1</td>\n      <td>2.9148</td>\n      <td>c1</td>\n      <td>190</td>\n      <td>0</td>\n      <td>c4</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>26360 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "f10(train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train = encoder(train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Users/unajun/.virtualenvs/CSED490_Project/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "train = remove_unknown(train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train = train.apply(pd.to_numeric)\n",
    "# train[(np.abs(stats.zscore(train)) < 3).all(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "f1     0\nf2     0\nf3     0\nf4     0\nf5     0\nf6     0\nf7     0\nf8     0\nf9     0\nf10    0\nf11    0\nf12    0\nf13    0\nf14    0\nf15    0\nf16    0\nf17    0\nf18    0\nf19    0\nf20    0\ny      0\ndtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "train.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26302 entries, 0 to 26359\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   f1      26302 non-null  int64  \n",
      " 1   f2      26302 non-null  int64  \n",
      " 2   f3      26302 non-null  int64  \n",
      " 3   f4      26302 non-null  int64  \n",
      " 4   f5      26302 non-null  int64  \n",
      " 5   f6      26302 non-null  int64  \n",
      " 6   f7      26302 non-null  int64  \n",
      " 7   f8      26302 non-null  int64  \n",
      " 8   f9      26302 non-null  int64  \n",
      " 9   f10     26302 non-null  int64  \n",
      " 10  f11     26302 non-null  float64\n",
      " 11  f12     26302 non-null  int64  \n",
      " 12  f13     26302 non-null  float64\n",
      " 13  f14     26302 non-null  float64\n",
      " 14  f15     26302 non-null  float64\n",
      " 15  f16     26302 non-null  float64\n",
      " 16  f17     26302 non-null  int64  \n",
      " 17  f18     26302 non-null  int64  \n",
      " 18  f19     26302 non-null  int64  \n",
      " 19  f20     26302 non-null  int64  \n",
      " 20  y       26302 non-null  int64  \n",
      "dtypes: float64(5), int64(16)\n",
      "memory usage: 4.4 MB\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(26302, 21)\n",
      "(21222, 21)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "(_, quant) = catagorize(train)\n",
    "print(train.shape)\n",
    "from scipy import stats\n",
    "for x in quant:\n",
    "    train = train[np.abs(train[x]-train[x].mean()) <= (3*train[x].std())]\n",
    "print(train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "       f1  f2  f3  f4  f5  f6  f7  f8  f9  f10  ...  f12      f13    f14  f15  \\\n0       3   0   0   7  53   1   0   3   2    2  ...    1  65.7426 -34.16  1.4   \n2       0   0   0   6  29   1   0   2   2    2  ...    0  65.0251 -36.96 -1.8   \n3       1   0   0   2  25   2   1   3   2    2  ...    1  65.7426 -34.16  1.4   \n4       8   0   0   6  40   3   0   0   2    2  ...    1  65.1525 -37.68 -1.8   \n5       9   1   2   2  28   1   0   4   2    2  ...    0  65.7958 -29.12  1.1   \n...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...      ...    ...  ...   \n26355   1   1   0   0  28   1   0   4   0    2  ...    0  65.7426 -34.16  1.4   \n26356  11   1   2   2  31   9   0   0   1    2  ...    1  65.7958 -29.12  1.1   \n26357   6   1   2   3  33   1   0   2   1    2  ...    1  65.7958 -29.12  1.1   \n26358  11   0   0   7  53   6   0   0   0    2  ...    1  65.0251 -36.96 -1.8   \n26359   9   1   0   3  30   2   0   2   2    2  ...    1  65.7958 -29.12  1.1   \n\n          f16  f17  f18  f19  f20  y  \n0      2.9772    1  343    0    6  0  \n2      0.8004    0  401    1    4  0  \n3      2.9772    1  212    0    6  0  \n4      0.8430    1  379    0    3  0  \n5      2.9130    1  646    0    4  0  \n...       ...  ...  ...  ...  ... ..  \n26355  2.9754    1  327    0    6  0  \n26356  2.9148    1  179    0    4  0  \n26357  2.9148    1  641    0    4  0  \n26358  0.7464    1   35    0    4  0  \n26359  2.9148    1  190    0    4  0  \n\n[21222 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>f5</th>\n      <th>f6</th>\n      <th>f7</th>\n      <th>f8</th>\n      <th>f9</th>\n      <th>f10</th>\n      <th>...</th>\n      <th>f12</th>\n      <th>f13</th>\n      <th>f14</th>\n      <th>f15</th>\n      <th>f16</th>\n      <th>f17</th>\n      <th>f18</th>\n      <th>f19</th>\n      <th>f20</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>53</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>65.7426</td>\n      <td>-34.16</td>\n      <td>1.4</td>\n      <td>2.9772</td>\n      <td>1</td>\n      <td>343</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>29</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>65.0251</td>\n      <td>-36.96</td>\n      <td>-1.8</td>\n      <td>0.8004</td>\n      <td>0</td>\n      <td>401</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>25</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>65.7426</td>\n      <td>-34.16</td>\n      <td>1.4</td>\n      <td>2.9772</td>\n      <td>1</td>\n      <td>212</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>40</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>65.1525</td>\n      <td>-37.68</td>\n      <td>-1.8</td>\n      <td>0.8430</td>\n      <td>1</td>\n      <td>379</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>9</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>28</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>65.7958</td>\n      <td>-29.12</td>\n      <td>1.1</td>\n      <td>2.9130</td>\n      <td>1</td>\n      <td>646</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26355</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>28</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>65.7426</td>\n      <td>-34.16</td>\n      <td>1.4</td>\n      <td>2.9754</td>\n      <td>1</td>\n      <td>327</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26356</th>\n      <td>11</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>31</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>65.7958</td>\n      <td>-29.12</td>\n      <td>1.1</td>\n      <td>2.9148</td>\n      <td>1</td>\n      <td>179</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26357</th>\n      <td>6</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>33</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>65.7958</td>\n      <td>-29.12</td>\n      <td>1.1</td>\n      <td>2.9148</td>\n      <td>1</td>\n      <td>641</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26358</th>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>53</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>65.0251</td>\n      <td>-36.96</td>\n      <td>-1.8</td>\n      <td>0.7464</td>\n      <td>1</td>\n      <td>35</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26359</th>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>30</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>65.7958</td>\n      <td>-29.12</td>\n      <td>1.1</td>\n      <td>2.9148</td>\n      <td>1</td>\n      <td>190</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>21222 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 15
    }
   ],
   "source": [
    "train.loc[train['y'] == 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "y = train.y\n",
    "X = train.drop('y', axis =1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Users/unajun/.virtualenvs/CSED490_Project/lib/python3.7/site-packages/statsmodels/base/model.py:1362: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "/Users/unajun/.virtualenvs/CSED490_Project/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/Users/unajun/.virtualenvs/CSED490_Project/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/Users/unajun/.virtualenvs/CSED490_Project/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-20fb30c89a8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mX_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mpmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfeature_with_p_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/CSED490_Project/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    290\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                         raise ValueError(\n\u001b[0;32m--> 292\u001b[0;31m                             \u001b[0;34mf\"Length of passed values is {len(data)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m                             \u001b[0;34mf\"index implies {len(index)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                         )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of passed values is 19, index implies 20."
     ],
     "ename": "ValueError",
     "evalue": "Length of passed values is 19, index implies 20.",
     "output_type": "error"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_1 = sm.add_constant(X)\n",
    "#Fitting sm.OLS model\n",
    "model = sm.OLS(y,X_1).fit()\n",
    "model.pvalues\n",
    "\n",
    "cols = list(X.columns)\n",
    "pmax = 1\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = X[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(y,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "selected_features_BE = cols\n",
    "print(selected_features_BE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "reg = LassoCV()\n",
    "y = train.y\n",
    "X = train.drop('y', axis =1)\n",
    "reg.fit(X, y)\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %reg.score(X,y))\n",
    "coef = pd.Series(reg.coef_, index = X.columns)\n",
    "\n",
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n",
    "\n",
    "imp_coef = coef.sort_values()\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Model\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = train['y'].values\n",
    "X = train.drop('y', axis=1)\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(13).plot(kind='barh')\n",
    "plt.show()\n",
    "# feat_importances.get_figure.savefig(\"feature.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('Decison-Tree', DecisionTreeClassifier()))\n",
    "models.append(('SVM', SVC()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "backward_elmin = ['f2', 'f3','f10', 'f11', 'f13', 'f15', 'f16', 'f17', 'f18', 'f19']\n",
    "decision_tree = [18, 16, 5, 6, 1, 4, 11, 8, 10, 9, 12 , 17, 15]\n",
    "lasso = ['f14', 'f20',  'f18', 'f11']\n",
    "input_col = [\"f\"+str(i) for i in decision_tree]\n",
    "\n",
    "y = train['y'].values\n",
    "X = train[input_col]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_train = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=len(input_col))\n",
    "pca.fit(X_train)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "cnt = 1\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=len(input_col))\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"{}/{}\\t{}: {}\".format(cnt, len(models), name, cv_results.mean())\n",
    "    cnt+=1;\n",
    "    print(msg)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "val_x = pd.read_csv('data/classificaition_val_x.csv')\n",
    "val_y = pd.read_csv('data/classificaition_val_y.csv')\n",
    "\n",
    "f10(val_x)\n",
    "val_x = encoder(val_x)\n",
    "val_x = val_x.apply(pd.to_numeric)\n",
    "val_x[(np.abs(stats.zscore(val_x)) < 3).all(axis=1)]\n",
    "\n",
    "scaler.fit(val_x)\n",
    "val_x = scaler.fit_transform(val_x)\n",
    "pca.fit(val_x)\n",
    "val_x = pca.fit_transform(val_x)\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y)\n",
    "predictions = svc.predict(val_x)\n",
    "print(\"Accuracy : \", accuracy_score(val_y, predictions))\n",
    "print(\"Confusion Matrix : \\n\",confusion_matrix(val_y, predictions))\n",
    "print(\"Classification Report: \\n\",classification_report(val_y, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def underSampling (data_df):\n",
    "\n",
    "    print (\"Inside Undersampling\")\n",
    "    # Lets shuffle the data before creating the subsamples\n",
    "    data_df.sample(frac=1)\n",
    "    # count the number of records having personal loan as 1 from the dataframe \n",
    "    count = data_df[data_df[\"y\"] == 1][\"y\"].count()\n",
    "    # match and select same number of records for both the targets.\n",
    "    outcome_True_df     = data_df.loc[data_df['y'] == 1]\n",
    "    outcome_False_df    = data_df.loc[data_df['y'] == 0][:count]\n",
    "    #merge the classes with equal number of records\n",
    "    normal_distributed_df = pd.concat([outcome_True_df, outcome_False_df])\n",
    "    # Shuffle dataframe rows\n",
    "    balanced_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "    return balanced_df\n",
    "\n",
    "def cal_accuracy(y_test, y_pred): \n",
    "      \n",
    "    print(\"Confusion Matrix: \", \n",
    "        metrics.confusion_matrix(y_test, y_pred)) \n",
    "      \n",
    "    print (\"Accuracy : \", \n",
    "    metrics.accuracy_score(y_test,y_pred)*100) \n",
    "    \n",
    "    print(\"Recall: {:.2f}\".format(metrics.recall_score(y_test, y_pred)))\n",
    "    print(\"Precision: {:.2f}\".format(metrics.precision_score(y_test, y_pred)))\n",
    "      \n",
    "    print(\"Report : \", \n",
    "    metrics.classification_report(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "def splitdataset(data_df, label, t_size):\n",
    "         # Seperating the target variable\n",
    "    data_df.head()\n",
    "    Y = data_df[label]\n",
    "    data_df.drop(label,axis=1,inplace=True)\n",
    "    X = data_df\n",
    "    #print (\"inside split data set\", Y.unique())  \n",
    "    # Spliting the dataset into train and test \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = t_size, random_state = 100) \n",
    "    #print (\"inside split data set###\")    \n",
    "    return X, Y, X_train, X_test, y_train, y_test\n",
    "\n",
    "train_x = pd.read_csv('data/classificaition_train_x.csv')\n",
    "train_y = pd.read_csv('data/classificaition_train_y.csv')\n",
    "val_x = pd.read_csv('data/classificaition_val_x.csv')\n",
    "val_y = pd.read_csv('data/classificaition_val_y.csv')\n",
    "\n",
    "new_df = bank_df[input_col].copy()\n",
    "label = \"Target\"\n",
    "# undersample the train data\n",
    "new_df = underSampling(new_df)\n",
    "t_size = 0.3 #Set the split ratio to 70:30\n",
    "# split the data set\n",
    "X, Y, X_train, X_test, y_train, y_test = splitdataset(new_df,label,t_size)\n",
    "\n",
    "# Try with polynomial features (1)\n",
    "poly_features_1 = PolynomialFeatures(degree=1)\n",
    "\n",
    "\n",
    "X_train_poly1 = poly_features_1.fit_transform(X_train)\n",
    "\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(X_train_poly1, y_train)\n",
    "y_test_pred = logisticRegr.predict(poly_features_1.fit_transform(X_test))\n",
    "cal_accuracy(y_test, y_test_pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}